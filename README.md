# Big Data Cloud Group 1 - Deployment Guide

Detta √§r en steg-f√∂r-steg guide f√∂r att deploya v√•r Big Data-applikation till Azure med Terraform, Docker och Azure Container Instances.

---

## F√∂ruts√§ttningar

- Azure CLI installerat och inloggat (`az login`)
- Terraform installerat
- Docker Desktop installerat och ig√•ng
- Ett Azure-konto med en aktiv subscription

---

## Steg 1: Provisionera infrastruktur med Terraform

### 1.1 Navigera till Terraform-mappen

√ñppna en terminal (PowerShell eller CMD) och navigera till projektroten:

```powershell
cd C:\Users\alexa\Documents\big_data_cloud_group1\IaC_terraform
```
### 1.2 Initiera Terraform
```powershell
 terraform init
 ```

### 1.3 Planera infrastrukturen
Ers√§tt <ditt subscription ID> med ditt Azure Subscription ID och <ditt namn> med ditt namn:

```powershell
terraform plan -var="subscription_id=<ditt subscription ID>" -var="owner=<ditt namn>"
```

### 1.4 Applicera infrastrukturen
```powershell
terraform apply -auto-approve -var="subscription_id=<ditt subscription ID>" -var="owner=<ditt namn>"
```

## Steg 2: Uppdatera docker-compose.yml med ditt ACR-namn
### 2.1 Hitta ditt ACR-namn
G√• till Azure Portal ‚Üí Resource Groups ‚Üí grupp1-dashboard-rg ‚Üí Container Registry.

Kopiera namnet p√• din ACR (t.ex. acrgrupp1abc123).

## 2.2 Redigera docker-compose.yml
√ñppna filen docker-compose.yml i projektroten och s√§tt in ditt ACR-namn mellan image: och .azurecr.io/ p√• rad 8 och rad 16.

Exempel:

F√∂re:
```powershell
image: .azurecr.io/hr-pipeline:latest
```

Efter:
```powershell
image: acrgrupp1abc123.azurecr.io/hr-pipeline:latest
```
<img src="1.png" alt="Bild 1" width="700">

## Steg 3: Bygg Docker-images
Navigera till projektets root-mapp (d√§r docker-compose.yml ligger) och bygg alla images:
```powershell
cd C:\Users\alexa\Documents\big_data_cloud_group1
docker compose build
```

## Steg 4: Logga in p√• Azure Container Registry

### 4.1 H√§mta ACR-inloggningsuppgifter
G√• till Azure Portal ‚Üí din Container Registry ‚Üí Access keys (under Settings).
<img src="2.png" alt="Bild 1" width="700">

Kopiera:

Username (samma som ACR-namnet)
password (anv√§nd antingen password eller password2)

### 4.2 Logga in med Docker
Ers√§tt "ditt acr namn" med ditt ACR-namn:
```powershell
docker login <ditt acr namn>.azurecr.io
```
Ange username och password n√§r du blir ombedd.

## Steg 5: Pusha Docker-images till ACR
Ers√§tt "ditt acr namn" med ditt ACR-namn:
```powershell
docker push <ditt acr namn>.azurecr.io/hr-pipeline:latest
docker push <ditt acr namn>.azurecr.io/dashboard:latest
```

## Steg 6: Skapa Azure Container Instance f√∂r hr-pipeline

### 6.1 √ñppna Azure Cloud Shell
G√• till Azure Portal och klicka p√• Cloud Shell-ikonen (PowerShell) l√§ngst upp till h√∂ger.

### 6.2 K√∂r f√∂ljande kommando
‚ö†Ô∏è Viktigt: Byt ut f√∂ljande v√§rden mot dina egna (se markerade f√§lt i bild 3):

--name ‚Üí ditt ACR-namn (t.ex. acrgrupp1abc123)
--image ‚Üí "ditt acr namn".azurecr.io/hr-pipeline:latest
--registry-login-server ‚Üí "ditt acr namn".azurecr.io
--registry-username ‚Üí ditt ACR-namn
--registry-password ‚Üí ditt ACR-l√∂senord (fr√•n Access Keys)
--azure-file-volume-account-name ‚Üí ditt Storage Account-namn (hittas i portalen under Resource Group)
--azure-file-volume-account-key ‚Üí din Storage Account Access Key (hittas under Storage Account ‚Üí Access keys)

<img src="3.png" alt="Bild 1" width="700">

```powershell
az container create `
  --resource-group grupp1-dashboard-rg `
  --name <ditt acr namn> `
  --os-type Linux `
  --image <ditt acr namn>.azurecr.io/hr-pipeline:latest `
  --registry-login-server <ditt acr namn>.azurecr.io `
  --registry-username <ditt acr namn> `
  --registry-password "<ditt acr l√∂senord>" `
  --ip-address Public `
  --ports 80 3000 `
  --environment-variables `
      DBT_PROFILES_DIR="/mnt/data/.dbt" `
      DUCKDB_PATH="/mnt/data/job_ads.duckdb" `
  --azure-file-volume-share-name files `
  --azure-file-volume-account-name <ditt storage account namn> `
  --azure-file-volume-account-key "<din storage account access key>" `
  --azure-file-volume-mount-path /mnt/data `
  --cpu 1 `
  --memory 4
  ```

## Steg 7: K√∂r Dagster-pipeline
## 7.1 Hitta Container Instance URL
G√• till Azure Portal ‚Üí Resource Groups ‚Üí grupp1-dashboard-rg ‚Üí Container Instances ‚Üí klicka p√• din container.

Kopiera IP-adressen och l√§gg till :3000 p√• slutet i webbl√§saren:

http://<container-ip>:3000
## 7.2 Materialisera data i Dagster UI
I Dagster UI:

Klicka p√• "Materialize all" f√∂r att k√∂ra hela pipelinen.
V√§nta tills alla jobb √§r klara.
## 7.3 Verifiera att DuckDB-filen skapades
G√• till Azure Portal ‚Üí Storage Account ‚Üí File shares ‚Üí files.

Du ska nu se filen job_ads.duckdb i mappen.
<img src="4.png" alt="Bild 1" width="700">

## Steg 8: √ñppna Dashboard (Streamlit App)
### 8.1 Hitta App Service URL
G√• till Azure Portal ‚Üí Resource Groups ‚Üí grupp1-dashboard-rg ‚Üí App Service.

Klicka p√• URL:en (t.ex. https://grupp1-dashboard-appxyz.azurewebsites.net).

Din Streamlit-dashboard ska nu vara live! üéâ

## Fels√∂kning
### Problem: Container Instance startar inte
Kontrollera att ACR-l√∂senordet och Storage Account-nyckeln √§r korrekta.
Kolla loggar i Azure Portal under Container Instance ‚Üí Logs.
### Problem: Dashboard visar ingen data
Se till att Dagster-pipelinen har k√∂rts klart och att job_ads.duckdb finns i File Share.
Restart App Service via Azure Portal.
### Problem: Docker push misslyckas
Kontrollera att du √§r inloggad p√• r√§tt ACR: docker login <ditt acr namn>.azurecr.io
Verifiera att image-namnen i docker-compose.yml matchar ditt ACR-namn.
## Rensa resurser (n√§r du √§r klar)
F√∂r att ta bort alla Azure-resurser och undvika kostnader:
```powershell
cd C:\Users\alexa\Documents\big_data_cloud_group1\IaC_terraform
terraform destroy -var="subscription_id=<ditt subscription ID>" -var="owner=<ditt namn>"
```

## Tack f√∂r oss!
### H√§lsningar fr√•n Alex, Erik & Eyoub
# HR Analytics ‚Äì Cloud Deployment  

This project builds upon our earlier project <a href="https://github.com/AlejandroHiroshima/Data_warehouse_grupp4_DE24" target="_blank" rel="noopener noreferrer">
  HR Analytics Proof of Concept ‚Üó
</a>, which implemented a modern data stack for analyzing job advertisements from Arbetsf√∂rmedlingen JobTech API. 
The previous version used DLT for ingestion, DBT for data transformation, and Streamlit for dashboard visualization within a local environment and Snowflake-based data warehouse.
In this continuation, the solution is extended to a cloud-based deployment on Microsoft Azure, leveraging:
  
- Terraform for Infrastructure as Code (IaC)
- Azure Container Registry (ACR) and App Service for hosting
- Dagster for orchestration
- DuckDB as the analytical data warehouse
  
This version emphasizes scalability, automation and cost efficiency, transforming the original proof of concept into a production-ready, reproducible cloud pipeline architecture.

### Project Architecture ###
| **Layer**              | **Technology / Tools**    | **Purpose**                            |
| ---------------------- | ------------------------- | -------------------------------------- |
| **Ingestion (EL)**     | DLT, Dagster              | Extracts job ad data from JobTech API  |
| **Transformation (T)** | DBT                       | Cleans, models, and creates data marts |
| **Storage (DW)**       | DuckDB (Azure File Share) | Lightweight data warehouse             |
| **Orchestration**      | Dagster                   | Automates daily ETL jobs               |
| **Visualization**      | Streamlit                 | Dashboard for HR analytics             |
| **Infrastructure**     | Terraform                 | Provisions and manages Azure resources |

### Azure Deployment Steps ###

                                                                            
### Cost Estimation 

Cost estimation are based on following assumptions: 

‚Ä¢	The DuckDB data warehouse is updated once per day as part of the scheduled ETL workflow.

‚Ä¢	The deployed Streamlit dashboard remains continuously available to users for real-time access and monitoring.

#### Azure + DuckDB cost estimation ### 

| **Type**                | **Estimated Monthly Cost (USD)** | **Description**                                     |
| ---------------------------- | -------------------------- | --------------------------------------------- |
| **App Service (P0v3)**           | ‚âà 64.97 $                |Hosts the Streamlit dashboard (24/7)                  |
| **Container Registry (Basic B1)**   | ‚âà 6 $                | Stores Docker images for pipeline & dashboard |
| **Storage account - Azure File Share (10 GB)**     | ‚âà 0.27 $                   | Stores DuckDB database & DBT profiles                     |
| **Container Instance (Dagster)** | ‚âà 1.01 $                    | Runs ETL job once per day (~30 min) daily 
| **Total / Month**            | **‚âà 72.25 $**            |                |

<sub>**Note:** The Dagster container is executed once per day (~30 minutes runtime), while the App Service runs continuously to keep the dashboard available 24/7.</sub>

#### Azure + Snowflake cost estimation

| Resource                          | Estimated Monthly Cost (USD) | Description                                 |
| --------------------------------- | ---------------------------- | ------------------------------------------- |
| **App Service (P0v3)**            | ‚âà 64.97 $                     | Hosts Streamlit dashboard (24/7)        |
| **Container Registry (Basic B1)** | ‚âà 6 $                    | Stores Docker images               |
| **Container Instance (Dagster)**  | ‚âà 1.01 $                     | Executes ETL orchestration once per day    |
| **Snowflake Warehouse (X-Small)** | ‚âà 15 $                    | Compute engine (1 credit/h √ó 7,5 h √ó $2). Runs 15 min daily    |
| **Snowflake Storage (~10 GB)**    | ‚âà 0.40 $                      | Cloud storage for raw & transformed tables |
| **Azure File Share**              | ‚Äî                            | Replaced by Snowflake storage.              |
| **Total / Month**                 | **‚âà 87.38 $**                | ‚âà +83 % vs DuckDB deployment.               |

### Pros and Cons 

| Aspect                         | **Azure + DuckDB**                       | **Azure + Snowflake**                        |
| ------------------------------ | ---------------------------------------- | -------------------------------------------- |
| **Cost**                       | ‚úÖ Low (~72 $  /mo)                     | ‚ùå Higher (~ 87 $/mo) due to compute billing   |
| **Performance**                | ‚ö†Ô∏è Limited to single process (embedded)  | ‚úÖ High performance with scalable compute     |
| **Concurrency**                | ‚ö†Ô∏è One user/process at a time for writes | ‚úÖ Supports many concurrent queries           |
| **Management**                 | ‚úÖ Simple (no server admin)               | ‚úÖ Fully managed but requires tuning costs    |
| **Scalability**                | ‚ö†Ô∏è Constrained by VM and file size       | ‚úÖ Elastic compute & storage scale separately |
| **Data sharing / integration** | ‚ùå Hard to share data externally          | ‚úÖ Built-in data sharing & governance         |
| **Latency**                    | ‚úÖ Low (local read access)                | ‚ö†Ô∏è Network latency to Snowflake region        |
| **Use case fit**               | Small team analytics / PoC / low cost    | Enterprise or multi-user production          |


### Project Structure Overview

``` 
BIG_DATA_CLOUD_GROUP1/
‚îú‚îÄ dagster_home/
‚îú‚îÄ dashboard/
‚îÇ  ‚îú‚îÄ connect_duck_pond.py
‚îÇ  ‚îú‚îÄ dashboard.py
‚îÇ  ‚îú‚îÄ plots.py
‚îÇ  ‚îî‚îÄ run_dashboard.py
‚îú‚îÄ data_extract_load/
‚îÇ  ‚îî‚îÄ load_job_ads.py
‚îú‚îÄ data_transformation/
‚îÇ  ‚îú‚îÄ models/
‚îÇ  ‚îÇ  ‚îú‚îÄ sources.yml
‚îÇ  ‚îÇ  ‚îú‚îÄ schema.yml
‚îÇ  ‚îÇ  ‚îú‚îÄ src_*.sql
‚îÇ  ‚îÇ  ‚îú‚îÄ dim_*.sql
‚îÇ  ‚îÇ  ‚îú‚îÄ fct_job_ads.sql
‚îÇ  ‚îÇ  ‚îî‚îÄ mart_*.sql
‚îÇ  ‚îú‚îÄ dbt_project.yml
‚îÇ  ‚îî‚îÄ profiles.yml
‚îú‚îÄ duck_pond/
‚îÇ  ‚îî‚îÄ job_ads.duckdb
‚îú‚îÄ orchestration/
‚îÇ  ‚îî‚îÄ definitions.py
‚îú‚îÄ IaC_terraform/
‚îÇ  ‚îú‚îÄ providers.tf
‚îÇ  ‚îú‚îÄ resource-group.tf
‚îÇ  ‚îú‚îÄ storage-account.tf
‚îÇ  ‚îú‚îÄ random.tf
‚îÇ  ‚îú‚îÄ input-variables.tf
‚îÇ  ‚îî‚îÄ outputs.tf
‚îú‚îÄ files/
‚îú‚îÄ logs/
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ dockerfile.dashboard
‚îú‚îÄ dockerfile.dwh
‚îú‚îÄ requirements.txt
‚îú‚îÄ requirements_mac.txt
‚îî‚îÄ README.md

```
