# Big Data Cloud Group 1 - Deployment Guide

Detta Ã¤r en steg-fÃ¶r-steg guide fÃ¶r att deploya vÃ¥r Big Data-applikation till Azure med Terraform, Docker och Azure Container Instances.

---

## FÃ¶rutsÃ¤ttningar

- Azure CLI installerat och inloggat (`az login`)
- Terraform installerat
- Docker Desktop installerat och igÃ¥ng
- Ett Azure-konto med en aktiv subscription

---

## Steg 1: Provisionera infrastruktur med Terraform

### 1.1 Navigera till Terraform-mappen

Ã–ppna en terminal (PowerShell eller CMD) och navigera till projektroten:

```powershell
cd C:\Users\alexa\Documents\big_data_cloud_group1\IaC_terraform
```
### 1.2 Initiera Terraform
```powershell
 terraform init
 ```

### 1.3 Planera infrastrukturen
ErsÃ¤tt <ditt subscription ID> med ditt Azure Subscription ID och <ditt namn> med ditt namn:

```powershell
terraform plan -var="subscription_id=<ditt subscription ID>" -var="owner=<ditt namn>"
```

### 1.4 Applicera infrastrukturen
```powershell
terraform apply -auto-approve -var="subscription_id=<ditt subscription ID>" -var="owner=<ditt namn>"
```

## Steg 2: Uppdatera docker-compose.yml med ditt ACR-namn
### 2.1 Hitta ditt ACR-namn
GÃ¥ till Azure Portal â†’ Resource Groups â†’ grupp1-dashboard-rg â†’ Container Registry.

Kopiera namnet pÃ¥ din ACR (t.ex. acrgrupp1abc123).

## 2.2 Redigera docker-compose.yml
Ã–ppna filen docker-compose.yml i projektroten och sÃ¤tt in ditt ACR-namn mellan image: och .azurecr.io/ pÃ¥ rad 8 och rad 16.

Exempel:

FÃ¶re:
```powershell
image: .azurecr.io/hr-pipeline:latest
```

Efter:
```powershell
image: acrgrupp1abc123.azurecr.io/hr-pipeline:latest
```
<img src="1.png" alt="Bild 1" width="700">

## Steg 3: Bygg Docker-images
Navigera till projektets root-mapp (dÃ¤r docker-compose.yml ligger) och bygg alla images:
```powershell
cd C:\Users\alexa\Documents\big_data_cloud_group1
docker compose build
```

## Steg 4: Logga in pÃ¥ Azure Container Registry

### 4.1 HÃ¤mta ACR-inloggningsuppgifter
GÃ¥ till Azure Portal â†’ din Container Registry â†’ Access keys (under Settings).
<img src="2.png" alt="Bild 1" width="700">

Kopiera:

Username (samma som ACR-namnet)
password (anvÃ¤nd antingen password eller password2)

### 4.2 Logga in med Docker
ErsÃ¤tt "ditt acr namn" med ditt ACR-namn:
```powershell
docker login <ditt acr namn>.azurecr.io
```
Ange username och password nÃ¤r du blir ombedd.

## Steg 5: Pusha Docker-images till ACR
ErsÃ¤tt "ditt acr namn" med ditt ACR-namn:
```powershell
docker push <ditt acr namn>.azurecr.io/hr-pipeline:latest
docker push <ditt acr namn>.azurecr.io/dashboard:latest
```

## Steg 6: Skapa Azure Container Instance fÃ¶r hr-pipeline

### 6.1 Ã–ppna Azure Cloud Shell
GÃ¥ till Azure Portal och klicka pÃ¥ Cloud Shell-ikonen (PowerShell) lÃ¤ngst upp till hÃ¶ger.

### 6.2 KÃ¶r fÃ¶ljande kommando
âš ï¸ Viktigt: Byt ut fÃ¶ljande vÃ¤rden mot dina egna (se markerade fÃ¤lt i bild 3):

--name â†’ ditt ACR-namn (t.ex. acrgrupp1abc123)
--image â†’ "ditt acr namn".azurecr.io/hr-pipeline:latest
--registry-login-server â†’ "ditt acr namn".azurecr.io
--registry-username â†’ ditt ACR-namn
--registry-password â†’ ditt ACR-lÃ¶senord (frÃ¥n Access Keys)
--azure-file-volume-account-name â†’ ditt Storage Account-namn (hittas i portalen under Resource Group)
--azure-file-volume-account-key â†’ din Storage Account Access Key (hittas under Storage Account â†’ Access keys)

<img src="3.png" alt="Bild 1" width="700">

```powershell
az container create `
  --resource-group grupp1-dashboard-rg `
  --name <ditt acr namn> `
  --os-type Linux `
  --image <ditt acr namn>.azurecr.io/hr-pipeline:latest `
  --registry-login-server <ditt acr namn>.azurecr.io `
  --registry-username <ditt acr namn> `
  --registry-password "<ditt acr lÃ¶senord>" `
  --ip-address Public `
  --ports 80 3000 `
  --environment-variables `
      DBT_PROFILES_DIR="/mnt/data/.dbt" `
      DUCKDB_PATH="/mnt/data/job_ads.duckdb" `
  --azure-file-volume-share-name files `
  --azure-file-volume-account-name <ditt storage account namn> `
  --azure-file-volume-account-key "<din storage account access key>" `
  --azure-file-volume-mount-path /mnt/data `
  --cpu 1 `
  --memory 4
  ```

## Steg 7: KÃ¶r Dagster-pipeline
## 7.1 Hitta Container Instance URL
GÃ¥ till Azure Portal â†’ Resource Groups â†’ grupp1-dashboard-rg â†’ Container Instances â†’ klicka pÃ¥ din container.

Kopiera IP-adressen och lÃ¤gg till :3000 pÃ¥ slutet i webblÃ¤saren:

http://<container-ip>:3000
## 7.2 Materialisera data i Dagster UI
I Dagster UI:

Klicka pÃ¥ "Materialize all" fÃ¶r att kÃ¶ra hela pipelinen.
VÃ¤nta tills alla jobb Ã¤r klara.
## 7.3 Verifiera att DuckDB-filen skapades
GÃ¥ till Azure Portal â†’ Storage Account â†’ File shares â†’ files.

Du ska nu se filen job_ads.duckdb i mappen.
<img src="4.png" alt="Bild 1" width="700">

## Steg 8: Ã–ppna Dashboard (Streamlit App)
### 8.1 Hitta App Service URL
GÃ¥ till Azure Portal â†’ Resource Groups â†’ grupp1-dashboard-rg â†’ App Service.

Klicka pÃ¥ URL:en (t.ex. https://grupp1-dashboard-appxyz.azurewebsites.net).

Din Streamlit-dashboard ska nu vara live! ğŸ‰

## FelsÃ¶kning
### Problem: Container Instance startar inte
Kontrollera att ACR-lÃ¶senordet och Storage Account-nyckeln Ã¤r korrekta.
Kolla loggar i Azure Portal under Container Instance â†’ Logs.
### Problem: Dashboard visar ingen data
Se till att Dagster-pipelinen har kÃ¶rts klart och att job_ads.duckdb finns i File Share.
Restart App Service via Azure Portal.
### Problem: Docker push misslyckas
Kontrollera att du Ã¤r inloggad pÃ¥ rÃ¤tt ACR: docker login <ditt acr namn>.azurecr.io
Verifiera att image-namnen i docker-compose.yml matchar ditt ACR-namn.
## Rensa resurser (nÃ¤r du Ã¤r klar)
FÃ¶r att ta bort alla Azure-resurser och undvika kostnader:
```powershell
cd C:\Users\alexa\Documents\big_data_cloud_group1\IaC_terraform
terraform destroy -var="subscription_id=<ditt subscription ID>" -var="owner=<ditt namn>"
```

## Tack fÃ¶r oss!
### HÃ¤lsningar frÃ¥n Alex, Erik & Eyoub
# HR Analytics â€“ Cloud Deployment  

This project builds upon our earlier project <a href="https://github.com/AlejandroHiroshima/Data_warehouse_grupp4_DE24" target="_blank" rel="noopener noreferrer">
  HR Analytics Proof of Concept â†—
</a>, which implemented a modern data stack for analyzing job advertisements from ArbetsfÃ¶rmedlingen JobTech API. 
The previous version used DLT for ingestion, DBT for data transformation, and Streamlit for dashboard visualization within a local environment and Snowflake-based data warehouse.
In this continuation, the solution is extended to a cloud-based deployment on Microsoft Azure, leveraging:
  
- Terraform for Infrastructure as Code (IaC)
- Azure Container Registry (ACR) and App Service for hosting
- Dagster for orchestration
- DuckDB as the analytical data warehouse
  
This version emphasizes scalability, automation and cost efficiency, transforming the original proof of concept into a production-ready, reproducible cloud pipeline architecture.

### Project Architecture ###
| **Layer**              | **Technology / Tools**    | **Purpose**                            |
| ---------------------- | ------------------------- | -------------------------------------- |
| **Ingestion (EL)**     | DLT, Dagster              | Extracts job ad data from JobTech API  |
| **Transformation (T)** | DBT                       | Cleans, models, and creates data marts |
| **Storage (DW)**       | DuckDB (Azure File Share) | Lightweight data warehouse             |
| **Orchestration**      | Dagster                   | Automates daily ETL jobs               |
| **Visualization**      | Streamlit                 | Dashboard for HR analytics             |
| **Infrastructure**     | Terraform                 | Provisions and manages Azure resources |

### Azure Deployment Steps ###

                                                                            
### Cost Estimation 

Cost estimation are based on following assumptions: 

â€¢	The DuckDB data warehouse is updated once per day as part of the scheduled ETL workflow.

â€¢	The deployed Streamlit dashboard remains continuously available to users for real-time access and monitoring.

#### Azure + DuckDB cost estimation ### 

| **Type**                | **Estimated Monthly Cost (USD)** | **Description**                                     |
| ---------------------------- | -------------------------- | --------------------------------------------- |
| **App Service (P0v3)**           | â‰ˆ 64.97 $                |Hosts the Streamlit dashboard (24/7)                  |
| **Container Registry (Basic B1)**   | â‰ˆ 6 $                | Stores Docker images for pipeline & dashboard |
| **Storage account - Azure File Share (10 GB)**     | â‰ˆ 0.27 $                   | Stores DuckDB database & DBT profiles                     |
| **Container Instance (Dagster)** | â‰ˆ 1.01 $                    | Runs ETL job once per day (~30 min) daily 
| **Total / Month**            | **â‰ˆ 72.25 $**            |                |

<sub>**Note:** The Dagster container is executed once per day (~30 minutes runtime), while the App Service runs continuously to keep the dashboard available 24/7.</sub>

#### Azure + Snowflake cost estimation

| Resource                          | Estimated Monthly Cost (USD) | Description                                 |
| --------------------------------- | ---------------------------- | ------------------------------------------- |
| **App Service (P0v3)**            | â‰ˆ 64.97 $                     | Hosts Streamlit dashboard (24/7)        |
| **Container Registry (Basic B1)** | â‰ˆ 6 $                    | Stores Docker images               |
| **Container Instance (Dagster)**  | â‰ˆ 1.01 $                     | Executes ETL orchestration once per day    |
| **Snowflake Warehouse (X-Small)** | â‰ˆ 15 $                    | Compute engine (1 credit/h Ã— 7,5 h Ã— $2). Runs 15 min daily    |
| **Snowflake Storage (~10 GB)**    | â‰ˆ 0.40 $                      | Cloud storage for raw & transformed tables |
| **Azure File Share**              | â€”                            | Replaced by Snowflake storage.              |
| **Total / Month**                 | **â‰ˆ 87.38 $**                | â‰ˆ +83 % vs DuckDB deployment.               |

### Pros and Cons 

| Aspect                         | **Azure + DuckDB**                       | **Azure + Snowflake**                        |
| ------------------------------ | ---------------------------------------- | -------------------------------------------- |
| **Cost**                       | âœ… Low (~72 $  /mo)                     | âŒ Higher (~ 87 $/mo) due to compute billing   |
| **Performance**                | âš ï¸ Limited to single process (embedded)  | âœ… High performance with scalable compute     |
| **Concurrency**                | âš ï¸ One user/process at a time for writes | âœ… Supports many concurrent queries           |
| **Management**                 | âœ… Simple (no server admin)               | âœ… Fully managed but requires tuning costs    |
| **Scalability**                | âš ï¸ Constrained by VM and file size       | âœ… Elastic compute & storage scale separately |
| **Data sharing / integration** | âŒ Hard to share data externally          | âœ… Built-in data sharing & governance         |
| **Latency**                    | âœ… Low (local read access)                | âš ï¸ Network latency to Snowflake region        |
| **Use case fit**               | Small team analytics / PoC / low cost    | Enterprise or multi-user production          |


### Project Structure Overview

``` 
BIG_DATA_CLOUD_GROUP1/
â”œâ”€ dagster_home/
â”œâ”€ dashboard/
â”‚  â”œâ”€ connect_duck_pond.py
â”‚  â”œâ”€ dashboard.py
â”‚  â”œâ”€ plots.py
â”‚  â””â”€ run_dashboard.py
â”œâ”€ data_extract_load/
â”‚  â””â”€ load_job_ads.py
â”œâ”€ data_transformation/
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ sources.yml
â”‚  â”‚  â”œâ”€ schema.yml
â”‚  â”‚  â”œâ”€ src_*.sql
â”‚  â”‚  â”œâ”€ dim_*.sql
â”‚  â”‚  â”œâ”€ fct_job_ads.sql
â”‚  â”‚  â””â”€ mart_*.sql
â”‚  â”œâ”€ dbt_project.yml
â”‚  â””â”€ profiles.yml
â”œâ”€ duck_pond/
â”‚  â””â”€ job_ads.duckdb
â”œâ”€ orchestration/
â”‚  â””â”€ definitions.py
â”œâ”€ IaC_terraform/
â”‚  â”œâ”€ providers.tf
â”‚  â”œâ”€ resource-group.tf
â”‚  â”œâ”€ storage-account.tf
â”‚  â”œâ”€ random.tf
â”‚  â”œâ”€ input-variables.tf
â”‚  â””â”€ outputs.tf
â”œâ”€ files/
â”œâ”€ logs/
â”œâ”€ docker-compose.yml
â”œâ”€ dockerfile.dashboard
â”œâ”€ dockerfile.dwh
â”œâ”€ requirements.txt
â”œâ”€ requirements_mac.txt
â””â”€ README.md

```
